{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Backprop Example\n",
    "### The Problem\n",
    "Given a set of student GRE, GPA, uni rank, predict if a student will get admitted.\n",
    "\n",
    "### The Theory\n",
    "Build a simple neural network that updates the weights using gradient descent and backpropagation.\n",
    "\n",
    "### How it works\n",
    "1. Randomly initialise the weights using the random function\n",
    "2. Run a forward pass through the neural network to generate a prediction\n",
    "3. When a prediction is incorrect, we will update the weights\n",
    "4. We run a backward pass to propagate the error back according to each node's contribution, and calculate delta w\n",
    "5. Edit the weights using the calculated delta w value\n",
    "6. Repeat steps 2-5 to train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_prep import features, targets, features_test, targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seed the random number generator\n",
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set hyperparameters\n",
    "\n",
    "# number of hidden units\n",
    "n_hidden = 2\n",
    "epochs = 10000\n",
    "learnrate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialise values\n",
    "\n",
    "# get number of records and deatures from the data\n",
    "n_records, n_features = features.shape\n",
    "# initialise last loss as None\n",
    "last_loss = None\n",
    "# Initialize weights\n",
    "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                        size=(n_features, n_hidden))\n",
    "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                         size=n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.27630002065852294\n",
      "Train loss:  0.26234383325962973\n",
      "Train loss:  0.25198020538763455\n",
      "Train loss:  0.24434338417929377\n",
      "Train loss:  0.23871681885367121\n",
      "Train loss:  0.23455229005454342\n",
      "Train loss:  0.23144711247759817\n",
      "Train loss:  0.229111266798629\n",
      "Train loss:  0.22733741993913803\n",
      "Train loss:  0.22597737454942038\n"
     ]
    }
   ],
   "source": [
    "# run the network\n",
    "\n",
    "# for each iteration\n",
    "for e in range(epochs):\n",
    "    # initialise Δw for both layers as zeros\n",
    "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
    "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)\n",
    "    # for each set of data\n",
    "    for x, y in zip(features.values, targets):\n",
    "        ## run a forward pass\n",
    "        # input to the hidden layer\n",
    "        hidden_input = np.dot(x, weights_input_hidden)\n",
    "        # output from the hidden layer\n",
    "        hidden_output = sigmoid(hidden_input)\n",
    "        # input to output layer\n",
    "        output_layer_in = np.dot(hidden_output, weights_hidden_output)\n",
    "        # output layer out\n",
    "        output = sigmoid(output_layer_in)\n",
    "\n",
    "        ## run a backward pass to improve the neural net\n",
    "        # calculate the prediction error\n",
    "        error = y - output\n",
    "\n",
    "        # calculate error term for the output unit\n",
    "        output_error_term = error * output * (1 - output)\n",
    "\n",
    "        ## propagate errors to hidden layer\n",
    "        # calculate the hidden layer's contribution to the error\n",
    "        hidden_error = np.dot(weights_hidden_output, output_error_term)\n",
    "        \n",
    "        # calculate the error term for the hidden layer\n",
    "        hidden_error_term = hidden_error * (hidden_output * (1 - hidden_output))\n",
    "        \n",
    "        # update the Δw values\n",
    "        del_w_hidden_output += output_error_term * hidden_output\n",
    "        del_w_input_hidden += hidden_error_term * x[:,None]\n",
    "\n",
    "    # update weights using the Δw values\n",
    "    weights_input_hidden += learnrate * del_w_input_hidden / n_records\n",
    "    weights_hidden_output += learnrate * del_w_hidden_output / n_records\n",
    "\n",
    "    # printing out the mean square error on the training set to see progress\n",
    "    if e % (epochs / 10) == 0:\n",
    "        hidden_output = sigmoid(np.dot(x, weights_input_hidden))\n",
    "        out = sigmoid(np.dot(hidden_output,\n",
    "                             weights_hidden_output))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run our test features through the neural network\n",
    "\n",
    "# manually run the test features through the hidden layer\n",
    "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
    "# manually run the output layer\n",
    "out = sigmoid(np.dot(hidden, weights_hidden_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.750\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy on test data\n",
    "\n",
    "# if the prediction is > 50%, set as True\n",
    "predictions = out > 0.5\n",
    "# get mean of all the predictions\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "# print the prediction accuracy\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
